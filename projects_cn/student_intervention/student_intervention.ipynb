{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位\n",
    "## 监督学习\n",
    "## 项目 2: 搭建一个学生干预系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欢迎来到机器学习工程师纳米学位的第二个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**'练习'**开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以**'TODO'**标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还**必须**回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以**'问题 X'**为标题。请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1 - 分类 vs. 回归\n",
    "*在这个项目中你的任务是找出那些如果不给予帮助，最重可能无法毕业的学生。你觉得这个问题是哪种类型的监督学习问题，是分类问题还是回归问题？为什么？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答案: **这个问题属于监督学习，因为是否可以毕业是外界给的评判结论，并不是机器通过自己学习总结的规律及结论。另外，这个问题属于分类问题，原因是是否能够毕业是个标签值（而且是个布尔类型的标签值，值域可以用“是”或“否”表示），不是实数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析数据\n",
    "运行下面区域的代码以载入学生数据集，以及一些此项目所需的Python库。注意数据集的最后一列`'passed'`是我们的预测的目标（表示学生是毕业了还是没有毕业），其他的列是每个学生的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# 载入所需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 载入学生数据集\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 分析数据\n",
    "我们首先通过调查数据，以确定有多少学生的信息，并了解这些学生的毕业率。在下面的代码单元中，你需要完成如下的运算：\n",
    "- 学生的总数， `n_students`。\n",
    "- 每个学生的特征总数， `n_features`。\n",
    "- 毕业的学生的数量， `n_passed`。\n",
    "- 未毕业的学生的数量， `n_failed`。\n",
    "- 班级的毕业率， `grad_rate`， 用百分数表示(%)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO： 计算学生的数量\n",
    "n_students = student_data.index.size\n",
    "\n",
    "# TODO： 计算特征数量\n",
    "n_features = student_data.columns.size - 1\n",
    "\n",
    "# TODO： 计算通过的学生数\n",
    "n_passed = student_data.passed[student_data.passed == 'yes'].size\n",
    "\n",
    "# TODO： 计算未通过的学生数\n",
    "n_failed = student_data.passed[student_data.passed == 'no'].size\n",
    "\n",
    "# TODO： 计算通过率\n",
    "grad_rate = n_passed*100.0 / (n_passed + n_failed)\n",
    "\n",
    "# 输出结果\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "在这个部分中，我们将要为建模、训练和测试准备数据\n",
    "### 识别特征和目标列\n",
    "你获取的数据中通常都会包含一些非数字的特征，这会导致一些问题，因为大多数的机器学习算法都会期望输入数字特征进行计算。\n",
    "\n",
    "运行下面的代码单元将学生数据分成特征和目标列看一看他们中是否有非数字特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# 提取特征列\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# 提取目标列 ‘passed’\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# 显示列的列表\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "# 将数据分割成特征数据和目标数据（即X_all 和 y_all）\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# 通过打印前5行显示特征信息\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理特征列\n",
    "\n",
    "正如你所见，我们这里有几个非数值的列需要做一定的转换！它们中很多是简单的`yes`/`no`，比如`internet`。这些可以合理地转化为`1`/`0`（二元值，binary）值。\n",
    "\n",
    "其他的列，如`Mjob`和`Fjob`，有两个以上的值，被称为_分类变量（categorical variables）_。处理这样的列的推荐方法是创建和可能值一样多的列（如：`Fjob_teacher`，`Fjob_other`，`Fjob_services`等），然后将其中一个的值设为`1`另外的设为`0`。\n",
    "\n",
    "这些创建的列有时候叫做 _虚拟变量（dummy variables）_，我们将用[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)函数来完成这个转换。运行下面代码单元的代码来完成这里讨论的预处理步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' 预处理学生数据，将非数字的二元特征转化成二元值（0或1），将分类的变量转换成虚拟变量\n",
    "    '''\n",
    "    \n",
    "    # 初始化一个用于输出的DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # 查看数据的每一个特征列\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # 如果数据是非数字类型，将所有的yes/no替换成1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # 如果数据类型是类别的（categorical），将它转换成虚拟变量\n",
    "        if col_data.dtype == object:\n",
    "            # 例子: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # 收集转换后的列\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_GP</th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_R</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_GT3</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_A</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  famsize_GT3  \\\n",
       "0          1          0      1      0   18          0          1            1   \n",
       "1          1          0      1      0   17          0          1            1   \n",
       "2          1          0      1      0   15          0          1            0   \n",
       "3          1          0      1      0   15          0          1            1   \n",
       "4          1          0      1      0   16          0          1            1   \n",
       "\n",
       "   famsize_LE3  Pstatus_A    ...     higher  internet  romantic  famrel  \\\n",
       "0            0          1    ...          1         0         0       4   \n",
       "1            0          0    ...          1         1         0       5   \n",
       "2            1          0    ...          1         1         0       4   \n",
       "3            0          0    ...          1         1         1       3   \n",
       "4            0          0    ...          1         0         0       4   \n",
       "\n",
       "   freetime  goout  Dalc  Walc  health  absences  \n",
       "0         3      4     1     1       3         6  \n",
       "1         3      3     1     1       3         4  \n",
       "2         3      2     2     3       3        10  \n",
       "3         2      2     1     1       5         2  \n",
       "4         3      2     1     2       5         4  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现: 将数据分成训练集和测试集\n",
    "现在我们已经将所有的 _分类的（categorical）_ 特征转换成数值了。下一步我们将把数据（包括特征和对应的标签数据）分割成训练集和测试集。在下面的代码单元中，你需要完成下列功能：\n",
    "- 随机混洗（shuffle）切分数据(`X_all`, `y_all`) 为训练子集和测试子集。\n",
    "  - 使用300个数据点作为训练集（约75%），使用95个数据点作为测试集（约25%）。\n",
    "  - 如果可能的话，为你使用的函数设置一个`random_state`。\n",
    "  - 将结果存储在`X_train`, `X_test`, `y_train`和 `y_test`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    }
   ],
   "source": [
    "# TODO：在这里导入你可能需要使用的另外的功能\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO：设置训练集的数量\n",
    "num_train = 300\n",
    "\n",
    "# TODO：设置测试集的数量\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO：把数据集混洗和分割成上面定义的训练集和测试集\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all,test_size=num_test*1.0/(num_train+num_test),random_state=20)\n",
    "# 显示分割的结果\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评价模型\n",
    "在这个部分，你将选择3个适合这个问题并且在`scikit-learn`中已有的监督学习的模型。首先你需要说明你选择这三个模型的原因，包括这些数据集有哪些特点，每个模型的优点和缺点各是什么。然后，你需要将这些模型用不同大小的训练集（100个数据点，200个数据点，300个数据点）进行训练，并用F<sub>1</sub>的值来衡量。你需要制作三个表，每个表要显示训练集大小，训练时间，预测时间，训练集上的F<sub>1</sub>值和测试集上的F<sub>1</sub>值（每个模型一个表）。\n",
    "\n",
    "**这是目前** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **里有的监督学习模型，你可以从中选择:**\n",
    "- Gaussian Naive Bayes (GaussianNB) 朴素贝叶斯\n",
    "- Decision Trees 决策树\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent (SGDC)\n",
    "- Support Vector Machines (SVM) 向量模型机\n",
    "- Logistic Regression 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2 - 应用模型\n",
    "*列出三个适合这个问题的监督学习算法模型。每一个你选择的模型：*\n",
    "\n",
    "- 描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）\n",
    "- 这个模型的优势是什么？他什么情况下表现最好？\n",
    "- 这个模型的缺点是什么？什么条件下它表现很差？\n",
    "- 根据我们当前数据集的特点，为什么这个模型适合这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **  \n",
    "**逻辑回归**  \n",
    "- 逻辑回归的应用场景之一是做广告是否点击预测。引用出处https://cloud.baidu.com/doc/BML/ScenarioTutorial.html  \n",
    "- 逻辑回归属于线性算法的一种，具有模型简单、训练时间短、容易解释等优势。逻辑回归擅长分析线性关系，对于特征与结果之间呈现线性关系的场景表现较好，另外因为其训练与预测的速度都特别快，所以非常适合于大规模数据场景下使用。  \n",
    "- 逻辑回归的缺点在于容易欠拟合，对极值比较敏感，分类精度可能不高。逻辑回归在非线性特征较多的场景下表现很差。  \n",
    "- 当前数据集的特点是数据集规模小（只有395行），数据特征少（48个），数据特征既有标量特征又有实值特征，总体上是个简单的分类问题，可以使用逻辑回归来解决  \n",
    "---\n",
    "**集成方法（AdaBoost，Gradient Boosting）**  \n",
    "- 集成方法被广泛应用到各种场景，用来提升单个模型的精度，应用例子：预测红酒的口感，引用出处Michael Bowles 的书《Machine Learning In Python》第六章https://www.amazon.com/Machine-Learning-Python-Techniques-Predictive/dp/1118961749/ref=sr_1_1?s=books&ie=UTF8&qid=1429853783&sr=1-1&keywords=machine+learning+in+python\n",
    "- 集成方法的优势是泛化错误率低，精度高，不易过拟合。集成方法比较适用于行比列多很多的复杂问题（非线性模型）  \n",
    "- 集成方法的缺点是对离群值比较敏感，对于列比行多的情况下，集成方法表现较差。 \n",
    "- 当前数据集的特点是数据集规模小（只有395行），数据特征少（48个），总体上行比列多，虽然并不是复杂问题，但是集成方法同样可以处理\n",
    "---\n",
    "**SVM**  \n",
    "- SVM被广泛应用于解决各种“分类”问题，应用例子：手写数字识别问题，引用出处Peter Harringto 的书《机器学习实战》第6章 https://www.amazon.cn/%E5%9B%BE%E4%B9%A6/dp/B00D747PTK\n",
    "- SVM的优势在于可以解决高维问题，能够处理非线性特征的相互作用，无需依赖整个数据，泛化能力强。SVM特别适用于处理特征特别多的分类问题\n",
    "- SVM的缺点在于对缺失数据敏感，对核函数的选择敏感，有时候很难找到一个合适的核函数。SVM不适合缺失数据太多的数据集，如果核函数选择不当，效果非常差\n",
    "- 当前数据集的特点是数据集规模小（只有395行），数据特征少（48个），是个二元分类问题，没有缺失数据，SVM适用于解决这种分类问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备\n",
    "运行下面的代码单元以初始化三个帮助函数，这三个函数将能够帮你训练和测试你上面所选择的三个监督学习算法。这些函数是：\n",
    "- `train_classifier` - 输入一个分类器和训练集，用数据来训练这个分类器。\n",
    "- `predict_labels` - 输入一个训练好的分类器、特征以及一个目标标签，这个函数将帮你做预测并给出F<sub>1</sub>的值.\n",
    "- `train_predict` - 输入一个分类器以及训练集和测试集，它可以运行`train_clasifier`和`predict_labels`.\n",
    " - 这个函数将分别输出训练集的F<sub>1</sub>值和测试集的F<sub>1</sub>值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' 用训练集训练分类器 '''\n",
    "    \n",
    "    # 开始计时，训练分类器，然后停止计时\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "    \n",
    "    return \"{:.4f}\".format(end-start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' 用训练好的分类器做预测并输出F1值'''\n",
    "    \n",
    "    # 开始计时，作出预测，然后停止计时\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # 输出并返回结果\n",
    "    run_time = \"{:.4f}\".format(end - start)\n",
    "    score = \"{:.4f}\".format(f1_score(target.values, y_pred, pos_label='yes'))\n",
    "    print \"Made predictions in {} seconds.\".format(run_time)\n",
    "    return (run_time,score)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' 用一个分类器训练和预测，并输出F1值 '''\n",
    "    \n",
    "    li = []\n",
    "    # 输出分类器名称和训练集大小\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    li.append(len(X_train))\n",
    "    # 训练一个分类器\n",
    "    run_time = train_classifier(clf, X_train, y_train)\n",
    "    li.append(run_time)\n",
    "    \n",
    "    pred_time_train,score_train = predict_labels(clf, X_train, y_train)\n",
    "    pred_time_test,score_test = predict_labels(clf, X_test, y_test)\n",
    "    \n",
    "    li.append(pred_time_test)\n",
    "    li.append(score_train)\n",
    "    li.append(score_test)\n",
    "    # 输出训练和测试的预测结果\n",
    "    print \"F1 score for training set: {}.\".format(score_train)\n",
    "    print \"F1 score for test set: {}.\".format(score_test)\n",
    "    \n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 模型评价指标\n",
    "借助于上面定义的函数，你现在需要导入三个你选择的监督学习模型，然后为每一个模型运行`train_predict`函数。请记住，对于每一个模型你需要在不同大小的训练集（100，200和300）上进行训练和测试。所以，你在下面应该会有9个不同的输出（每个模型都有训练集大小不同的三个输出）。在接下来的代码单元中，你将需要实现以下功能：\n",
    "- 引入三个你在上面讨论过的监督式学习算法模型。\n",
    "- 初始化三个模型并将它们存储在`clf_A`， `clf_B` 和 `clf_C`中。\n",
    " - 如果可能对每一个模型都设置一个`random_state`。\n",
    " - **注意:** 这里先使用每一个模型的默认参数，在接下来的部分中你将需要对某一个模型的参数进行调整。\n",
    "- 创建不同大小的训练集用来训练每一个模型。\n",
    " - *不要再混洗和再分割数据！新的训练集要取自`X_train`和`y_train`.*\n",
    "- 对于每一个模型要用不同大小的训练集来训练它，然后在测试集上做测试（总共需要9次训练测试）   \n",
    "**注意:** 在下面的代码单元后面我们提供了三个表用来存储你的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 100. . .\n",
      "Trained model in 0.8704 seconds\n",
      "Made predictions in 0.1246 seconds.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.9536.\n",
      "F1 score for test set: 0.7338.\n",
      "Training a LogisticRegression using a training set size of 200. . .\n",
      "Trained model in 0.0050 seconds\n",
      "Made predictions in 0.0379 seconds.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.8707.\n",
      "F1 score for test set: 0.7586.\n",
      "Training a LogisticRegression using a training set size of 300. . .\n",
      "Trained model in 0.0065 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.8311.\n",
      "F1 score for test set: 0.8000.\n",
      "Training a AdaBoostClassifier using a training set size of 100. . .\n",
      "Trained model in 0.1538 seconds\n",
      "Made predictions in 0.0075 seconds.\n",
      "Made predictions in 0.0056 seconds.\n",
      "F1 score for training set: 0.9930.\n",
      "F1 score for test set: 0.7328.\n",
      "Training a AdaBoostClassifier using a training set size of 200. . .\n",
      "Trained model in 0.1304 seconds\n",
      "Made predictions in 0.0067 seconds.\n",
      "Made predictions in 0.0042 seconds.\n",
      "F1 score for training set: 0.8966.\n",
      "F1 score for test set: 0.7500.\n",
      "Training a AdaBoostClassifier using a training set size of 300. . .\n",
      "Trained model in 0.1123 seconds\n",
      "Made predictions in 0.0046 seconds.\n",
      "Made predictions in 0.0035 seconds.\n",
      "F1 score for training set: 0.8396.\n",
      "F1 score for test set: 0.8054.\n",
      "Training a GradientBoostingClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0375 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "F1 score for test set: 0.7612.\n",
      "Training a GradientBoostingClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0474 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.9858.\n",
      "F1 score for test set: 0.8299.\n",
      "Training a GradientBoostingClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0595 seconds\n",
      "Made predictions in 0.0007 seconds.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.9592.\n",
      "F1 score for test set: 0.8108.\n",
      "Training a LinearSVC using a training set size of 100. . .\n",
      "Trained model in 0.0055 seconds\n",
      "Made predictions in 0.0001 seconds.\n",
      "Made predictions in 0.0001 seconds.\n",
      "F1 score for training set: 0.9730.\n",
      "F1 score for test set: 0.6341.\n",
      "Training a LinearSVC using a training set size of 200. . .\n",
      "Trained model in 0.0126 seconds\n",
      "Made predictions in 0.0002 seconds.\n",
      "Made predictions in 0.0001 seconds.\n",
      "F1 score for training set: 0.8814.\n",
      "F1 score for test set: 0.7586.\n",
      "Training a LinearSVC using a training set size of 300. . .\n",
      "Trained model in 0.0243 seconds\n",
      "Made predictions in 0.0002 seconds.\n",
      "Made predictions in 0.0001 seconds.\n",
      "F1 score for training set: 0.8204.\n",
      "F1 score for test set: 0.7973.\n"
     ]
    }
   ],
   "source": [
    "# TODO：从sklearn中引入三个监督学习模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO：初始化三个模型\n",
    "\n",
    "clf_A = LogisticRegression(random_state = 0)\n",
    "clf_B = AdaBoostClassifier(random_state = 0)\n",
    "clf_C = GradientBoostingClassifier(random_state = 0)\n",
    "clf_D = LinearSVC(random_state = 0)\n",
    "\n",
    "\n",
    "# TODO：设置训练集大小\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "# TODO：对每一个分类器和每一个训练集大小运行'train_predict' \n",
    "# train_predict(clf_A, X_train_100, y_train_100, X_test, y_test)\n",
    "# train_predict(clf_A, X_train_200, y_train_200, X_test, y_test)\n",
    "# train_predict(clf_A, X_train_300, y_train_300, X_test, y_test)\n",
    "\n",
    "# train_predict(clf_B, X_train_100, y_train_100, X_test, y_test)\n",
    "# train_predict(clf_B, X_train_200, y_train_200, X_test, y_test)\n",
    "# train_predict(clf_B, X_train_300, y_train_300, X_test, y_test)\n",
    "\n",
    "# train_predict(clf_C, X_train_100, y_train_100, X_test, y_test)\n",
    "# train_predict(clf_C, X_train_200, y_train_200, X_test, y_test)\n",
    "# train_predict(clf_C, X_train_300, y_train_300, X_test, y_test)\n",
    "\n",
    "cols = ['训练集大小','训练时间','预测时间 (测试)','F1值 (训练)','F1值 (测试)']\n",
    "\n",
    "def model_train_predict(model):\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    li_100 = train_predict(model, X_train_100, y_train_100, X_test, y_test)\n",
    "    li_200 = train_predict(model, X_train_200, y_train_200, X_test, y_test)\n",
    "    li_300 = train_predict(model, X_train_300, y_train_300, X_test, y_test)\n",
    "\n",
    "    df = df.append(pd.DataFrame([li_100],columns=cols),ignore_index=True)\n",
    "    df = df.append(pd.DataFrame([li_200],columns=cols),ignore_index=True)\n",
    "    df = df.append(pd.DataFrame([li_300],columns=cols),ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_A = model_train_predict(clf_A)\n",
    "df_B = model_train_predict(clf_B)\n",
    "df_C = model_train_predict(clf_C)\n",
    "df_D = model_train_predict(clf_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# clf_E = GradientBoostingClassifier(random_state = 0)\n",
    "\n",
    "# cols = ['训练集大小','训练时间','预测时间 (测试)','F1值 (训练)','F1值 (测试)']\n",
    "\n",
    "# df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# li_100 = train_predict(clf_E, X_train_100, y_train_100, X_test, y_test)\n",
    "# li_200 = train_predict(clf_E, X_train_200, y_train_200, X_test, y_test)\n",
    "# li_300 = train_predict(clf_E, X_train_300, y_train_300, X_test, y_test)\n",
    "\n",
    "# df = df.append(pd.DataFrame([li_100],columns=cols),ignore_index=True)\n",
    "# df = df.append(pd.DataFrame([li_200],columns=cols),ignore_index=True)\n",
    "# df = df.append(pd.DataFrame([li_300],columns=cols),ignore_index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果表格\n",
    "编辑下面的表格看看在[Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables)中如何设计一个表格。你需要把上面的结果记录在表格中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 分类器 1 - 逻辑回归** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>训练集大小</th>\n",
       "      <th>训练时间</th>\n",
       "      <th>预测时间 (测试)</th>\n",
       "      <th>F1值 (训练)</th>\n",
       "      <th>F1值 (测试)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.7338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   训练集大小    训练时间 预测时间 (测试) F1值 (训练) F1值 (测试)\n",
       "0  100.0  0.8704    0.0004   0.9536   0.7338\n",
       "1  200.0  0.0050    0.0004   0.8707   0.7586\n",
       "2  300.0  0.0065    0.0003   0.8311   0.8000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 分类器 2 - 集成方法（AdaBoost）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>训练集大小</th>\n",
       "      <th>训练时间</th>\n",
       "      <th>预测时间 (测试)</th>\n",
       "      <th>F1值 (训练)</th>\n",
       "      <th>F1值 (测试)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.8054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   训练集大小    训练时间 预测时间 (测试) F1值 (训练) F1值 (测试)\n",
       "0  100.0  0.1538    0.0056   0.9930   0.7328\n",
       "1  200.0  0.1304    0.0042   0.8966   0.7500\n",
       "2  300.0  0.1123    0.0035   0.8396   0.8054"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 分类器 3 - 集成方法（GradientBoost）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>训练集大小</th>\n",
       "      <th>训练时间</th>\n",
       "      <th>预测时间 (测试)</th>\n",
       "      <th>F1值 (训练)</th>\n",
       "      <th>F1值 (测试)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.8299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.8108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   训练集大小    训练时间 预测时间 (测试) F1值 (训练) F1值 (测试)\n",
       "0  100.0  0.0375    0.0003   1.0000   0.7612\n",
       "1  200.0  0.0474    0.0003   0.9858   0.8299\n",
       "2  300.0  0.0595    0.0003   0.9592   0.8108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 分类器 4 - SVM（向量模型机）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>训练集大小</th>\n",
       "      <th>训练时间</th>\n",
       "      <th>预测时间 (测试)</th>\n",
       "      <th>F1值 (训练)</th>\n",
       "      <th>F1值 (测试)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.6341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8204</td>\n",
       "      <td>0.7973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   训练集大小    训练时间 预测时间 (测试) F1值 (训练) F1值 (测试)\n",
       "0  100.0  0.0055    0.0001   0.9730   0.6341\n",
       "1  200.0  0.0126    0.0001   0.8814   0.7586\n",
       "2  300.0  0.0243    0.0001   0.8204   0.7973"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最佳模型\n",
    "在最后这一部分中，你将从三个监督学习模型中选择一个用在学生数据上的最佳模型。然后你将在最佳模型上用全部的训练集（`X_train`和`y_train`）运行一个网格搜索算法，在这个过程中，你要至少调整一个参数以提高模型的F<sub>1</sub>值（相比于没有调参的模型的分值有所提高）。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3 - 选择最佳模型\n",
    "*给予你上面做的实验，用一到两段话，向（学校）监事会解释你将选择哪个模型作为最佳的模型。哪个模型在现有的数据，有限的资源、开支和模型表现综合来看是最好的选择？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **  \n",
    "\n",
    "我会选择集成方法(GradientBoost)作为最佳模型.原因有以下几点：\n",
    "- 从F1值来看，无论是训练集还是测试集，集成方法(GradientBoost)都具有最佳表现\n",
    "- 从F1值来看，无论是数据集规模大小，集成方法(GradientBoost)都具有最佳表现\n",
    "- 由于数据集整体规模较小，训练时间虽有差异，但是不成为关键要素，可以忽略\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4 - 用通俗的语言解释模型\n",
    "*用一到两段话，向（学校）监事会用外行也听得懂的话来解释最终模型是如何工作的。你需要解释所选模型的主要特点。例如，这个模型是怎样被训练的，它又是如何做出预测的。避免使用高级的数学或技术术语，不要使用公式或特定的算法名词。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **  \n",
    "集成方法(GradientBoost)是基于决策树的集成方法.决策树就是一个判断逻辑的集合,即如何符合XX条件,则结果是YY.  \n",
    "训练-预测过程大概是这样的:  \n",
    "- 首先根据已有数据训练出来一个简单的决策树模型,然后用模型做预测,将预测结果与实际结果做比较,找出其中差异，得到预测不准的部分\n",
    "- 对于预测不准的部分赋予更高的权重,然后再训练一个决策树模型，在训练中尽量向减少预测误差的方向优化,然后做预测，找差值，得到不准的部分\n",
    "- 继续循环上一步的训练-预测动作，直到达到模型数量阈值或者某个准确度\n",
    "- 将上述所有模型集成起来,做预测时,参考所有模型的权重和给出预测结果,加总汇集之后给出最终的预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习: 模型调参\n",
    "细调选择的模型的参数。使用网格搜索（`GridSearchCV`）来至少调整模型的重要参数（至少调整一个），这个参数至少需给出并尝试3个不同的值。你要使用整个训练集来完成这个过程。在接下来的代码单元中，你需要实现以下功能：\n",
    "- 导入 [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) 和 [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- 创建一个对于这个模型你希望调整参数的字典。\n",
    " - 例如: `parameters = {'parameter' : [list of values]}`。\n",
    "- 初始化你选择的分类器，并将其存储在`clf`中。\n",
    "- 使用`make_scorer` 创建F<sub>1</sub>评分函数并将其存储在`f1_scorer`中。\n",
    " - 需正确设定参数`pos_label`的值！\n",
    "- 在分类器`clf`上用`f1_scorer` 作为评价函数运行网格搜索,并将结果存储在`grid_obj`中。\n",
    "- 用训练集(`X_train`, `y_train`)训练grid search object,并将结果存储在`grid_obj`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0003 seconds.\n",
      "Made predictions in 0.0004 seconds.\n",
      "Tuned model has a training F1 score of 0.8356.\n",
      "Tuned model has a testing F1 score of 0.8366.\n"
     ]
    }
   ],
   "source": [
    "# TODO: 导入 'GridSearchCV' 和 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# TODO：创建你希望调整的参数列表\n",
    "# 适用于逻辑回归算法的参数\n",
    "# parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "parameters = {'max_depth':range(1,11)}\n",
    "# TODO：初始化分类器\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# TODO：用'make_scorer'创建一个f1评分函数\n",
    "f1_scorer = make_scorer(f1_score,pos_label='yes')\n",
    "\n",
    "# TODO：在分类器上使用f1_scorer作为评分函数运行网格搜索\n",
    "grid_obj = GridSearchCV(clf,parameters,f1_scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "# TODO：用训练集训练grid search object来寻找最佳参数\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "# 得到预测的结果\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "# 输出经过调参之后的训练集和测试集的F1值\n",
    "pred_time_train,score_train = predict_labels(clf, X_train, y_train)\n",
    "pred_time_test,score_test = predict_labels(clf, X_test, y_test)\n",
    "print \"Tuned model has a training F1 score of {}.\".format(score_train)\n",
    "print \"Tuned model has a testing F1 score of {}.\".format(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5 - 最终的 F<sub>1</sub> 值\n",
    "*最终模型的训练和测试的F<sub>1</sub>值是多少？这个值相比于没有调整过参数的模型怎么样？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答: **  \n",
    "最终模型训练的F1值为0.8356,测试的F1值为0.8366.相比于没有调参的模型(只跟训练集为300的数据对比),训练时的F1值由0.9592降低为0.8356，测试时3的F1值由0.8108提升为0.8366，训练和测试的F1值差值缩小，其结果是通过调参，修正了过拟合，增强了模型的泛化能力，进而提升了测试时的最终指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注意**: 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出**File -> Download as -> HTML (.html)**把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
